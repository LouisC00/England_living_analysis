{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8139182e-4fd0-4493-9c17-a6d9e91c0547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_message(user, message):\n",
    "    \"\"\"\n",
    "    Format a single message with the username and normalize UTF-8 encoding.\n",
    "    Replaces existing colons in the message to avoid ambiguity.\n",
    "    \"\"\"\n",
    "    if not isinstance(message, str):\n",
    "        message = \"\"\n",
    "    \n",
    "    # Normalize message to UTF-8\n",
    "    message = message.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    \n",
    "    # Replace existing colons to avoid ambiguity\n",
    "    message = message.replace(\":\", \" |\")\n",
    "    \n",
    "    # Format the message with the username\n",
    "    return f'{user}: {message}' if user else message\n",
    "\n",
    "def preprocess_messages_with_usernames(df):\n",
    "    \"\"\"\n",
    "    Preprocess messages by adding usernames and normalizing UTF-8 encoding.\n",
    "    Incorporates the original Filter 1 logic and adds selected stricter conditions\n",
    "    from Filter 2 (symbols_only, numeric_only, too_long, and suspicious links).\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the required columns exist\n",
    "    if \"Who\" not in df.columns or \"Chat Content\" not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'Who' and 'Chat Content' columns.\")\n",
    "\n",
    "    # Normalize 'Who' and 'Chat Content' to UTF-8\n",
    "    df['Who'] = df['Who'].apply(lambda x: x.encode(\"utf-8\").decode(\"utf-8\") if isinstance(x, str) else x)\n",
    "    df['Chat Content'] = df['Chat Content'].apply(lambda x: x.encode(\"utf-8\").decode(\"utf-8\") if isinstance(x, str) else \"\")\n",
    "\n",
    "    # Define the array of blocked phrases (original filter 1)\n",
    "    blocked_phrases = [\n",
    "        '首充入', '秒到帳', '每筆送', '獎金高達', '報名參加', '報名:', '報名：', '，報名', ', 報名', '優惠', '日期：', '時間：', '地點：', \n",
    "        '加入TG', '全文：', '報導', '當年今日', '現正招募', '專訪','拉群', '点我', '有意請', '立即申請：', '關注我們', '尋失物', 'LIHKG', \n",
    "        'lih.kg', 'play.google.com', 'Find out more', '得獎內容', '問卷連結', '公告：', 'Happy birthday', '生日快樂'\n",
    "    ]\n",
    "\n",
    "    # Define allowed domains for links (from filter 2)\n",
    "    allowed_domains = ['.uk', '.edu']\n",
    "\n",
    "    # Define conditions from original filter 1\n",
    "    cond_empty = df['Chat Content'].str.strip() == ''\n",
    "    cond_nan = df['Chat Content'].isna() | (df['Chat Content'].str.strip().str.upper() == 'NAN')\n",
    "    cond_link_only = df['Chat Content'].str.strip().str.match(r'^(https?://\\S+|www\\.\\S+)$', na=False)\n",
    "    cond_emoji_only = df['Chat Content'].str.match(r'^[\\U0001F300-\\U0001F6FF]+$', na=False)\n",
    "    cond_emoji_with_link = df['Chat Content'].str.match(r'^[\\U0001F300-\\U0001F6FF]+\\s+https?://\\S+$', na=False)\n",
    "    cond_who_contains_bot = df['Who'].str.contains('bot', case=False, na=False)\n",
    "    cond_blocked_phrases = df['Chat Content'].str.contains('|'.join(map(re.escape, blocked_phrases)), case=False, na=False)\n",
    "\n",
    "    # Calculate char count\n",
    "    df['CharCount'] = df['Chat Content'].str.len()\n",
    "\n",
    "    # Conditions from original filter 1\n",
    "    cond_two_hash_and_word_count = (\n",
    "        (df['Chat Content'].str.count('#') >= 2) & (df['CharCount'] > 80)\n",
    "    )\n",
    "\n",
    "    cond_instagram_and_facebook_words = (\n",
    "        df['Chat Content'].str.contains('instagram', case=False, na=False) & \n",
    "        df['Chat Content'].str.contains('facebook', case=False, na=False)\n",
    "    )\n",
    "\n",
    "    cond_instagram_and_facebook_links = (\n",
    "        df['Chat Content'].str.contains(r'instagram\\.com', case=False, na=False) & \n",
    "        df['Chat Content'].str.contains(r'facebook\\.com', case=False, na=False)\n",
    "    )\n",
    "\n",
    "    cond_instagram_and_facebook = cond_instagram_and_facebook_words | cond_instagram_and_facebook_links\n",
    "\n",
    "    cond_long_no_chinese = (df['CharCount'] > 700) & (~df['Chat Content'].str.contains(r'[\\u4e00-\\u9fff]', na=False))\n",
    "    cond_short_no_chinese = (df['CharCount'] == 1) & (~df['Chat Content'].str.contains(r'[\\u4e00-\\u9fff]', na=False))\n",
    "\n",
    "    # New conditions from filter 2 to include:\n",
    "    cond_symbols_only = df['Chat Content'].str.match(r'^[\\W_]+$', na=False)\n",
    "    cond_numeric_only = df['Chat Content'].str.match(r'^\\d+$', na=False)\n",
    "    cond_too_long = df['CharCount'] > 1000\n",
    "\n",
    "    # Suspicious links (no allowed domain), taken from filter 2 logic\n",
    "    cond_links_or_hashtags = (\n",
    "        df['Chat Content'].str.contains(r'(?:https?://|www\\.)', na=False) &\n",
    "        ~df['Chat Content'].str.contains('|'.join(map(re.escape, allowed_domains)), na=False)\n",
    "    )\n",
    "\n",
    "    # Remove rows where CharCount <= 5\n",
    "    cond_char_count_short = df['CharCount'] <= 5\n",
    "\n",
    "    # New condition: One or two English words with optional symbols or emojis\n",
    "    cond_one_two_words_with_emojis_or_symbols = df['Chat Content'].str.match(\n",
    "        r'^\\s*[\\W_]*[a-zA-Z]+(?:\\s+[a-zA-Z]+)?[\\W_]*\\s*$', na=False\n",
    "    )\n",
    "\n",
    "    # Combine all conditions using logical OR\n",
    "    # Update the combined mask\n",
    "    mask = (\n",
    "        cond_empty |\n",
    "        cond_nan |\n",
    "        cond_link_only |\n",
    "        cond_emoji_only |\n",
    "        cond_emoji_with_link |\n",
    "        cond_who_contains_bot |\n",
    "        cond_blocked_phrases |\n",
    "        cond_two_hash_and_word_count |\n",
    "        cond_instagram_and_facebook |\n",
    "        cond_long_no_chinese |\n",
    "        cond_short_no_chinese |\n",
    "        cond_symbols_only |\n",
    "        cond_numeric_only |\n",
    "        cond_too_long |\n",
    "        cond_links_or_hashtags |\n",
    "        cond_char_count_short |  # Add this condition\n",
    "        cond_one_two_words_with_emojis_or_symbols  # New condition\n",
    "    )\n",
    "\n",
    "    # Filter the DataFrame\n",
    "    df = df[~mask].copy()\n",
    "\n",
    "    # Preprocess messages (create 'Processed Content')\n",
    "    df[\"Processed Content\"] = df.apply(\n",
    "        lambda row: preprocess_message(row[\"Who\"], row[\"Chat Content\"]),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "159f1337-f7c0-4ae7-9e72-f0c38448bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Function to generate a random \"user\" ID\n",
    "def generate_user_id():\n",
    "    return f\"user{random.randint(10000, 99999)}\"\n",
    "\n",
    "# Function to assign random user IDs to empty rows in the 'Who' column\n",
    "def assign_user_ids(df, column_name):\n",
    "    current_user_id = None\n",
    "    for index in df.index:\n",
    "        if pd.isna(df.at[index, column_name]) or df.at[index, column_name] == \"\":  # Check if the column is empty\n",
    "            if current_user_id is None:\n",
    "                current_user_id = generate_user_id()\n",
    "            df.at[index, column_name] = current_user_id\n",
    "        else:\n",
    "            current_user_id = None  # Reset when encountering a non-empty row\n",
    "    return df\n",
    "\n",
    "# Main function to process the file\n",
    "def process_who_column(input_file):\n",
    "    # Load the CSV into a pandas DataFrame\n",
    "    df = pd.read_csv(input_file)\n",
    "    # Apply the function to assign user IDs\n",
    "    df = assign_user_ids(df, column_name='Who')\n",
    "    # Return the modified DataFrame\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb22582-6fde-485c-ad71-f8618b8d74d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = './9000_messages.csv'\n",
    "output_file = './9000_result.csv'\n",
    "df = process_who_column(input_file)\n",
    "\n",
    "df = preprocess_messages_with_usernames(df)\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3203fe24-2e8a-4763-ab0d-2c4cd7bbf8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
